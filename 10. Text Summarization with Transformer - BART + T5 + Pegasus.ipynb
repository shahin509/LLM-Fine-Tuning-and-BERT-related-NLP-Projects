{"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.9.14 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.14"},"vscode":{"interpreter":{"hash":"36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"13c185bb27074738998f4eb99c007505":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7597e26176f643a4873a9b11a5778af8","placeholder":"​","style":"IPY_MODEL_c02fa16b6d0a497e89e55c63b0427ddf","value":" 3/3 [00:00&lt;00:00,  2.75it/s]"}},"3ff1d017bfda485bb965e897f14e3f70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4008c0bbaea645a4bd95c26672cce12e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ccbc79e76f44dcf86ccc02be27b4910":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68cd6ca7aa40454195ccc26f9d870cb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ff1d017bfda485bb965e897f14e3f70","placeholder":"​","style":"IPY_MODEL_ae75682934dc4077967b76fdbd194233","value":"100%"}},"7597e26176f643a4873a9b11a5778af8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae50112f680e446e87368ad81147235e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68cd6ca7aa40454195ccc26f9d870cb8","IPY_MODEL_d7e6521389644dcaabe20c16fc20a3eb","IPY_MODEL_13c185bb27074738998f4eb99c007505"],"layout":"IPY_MODEL_5ccbc79e76f44dcf86ccc02be27b4910"}},"ae75682934dc4077967b76fdbd194233":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c02fa16b6d0a497e89e55c63b0427ddf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7e6521389644dcaabe20c16fc20a3eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef044cc6232249d4a80cb876dc889395","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4008c0bbaea645a4bd95c26672cce12e","value":3}},"ef044cc6232249d4a80cb876dc889395":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q","metadata":{"id":"4rQG3XA0vnS3"},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"\nfrom transformers import pipeline, set_seed\n\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\nfrom datasets import load_dataset, load_metric\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nimport pandas as pd\nimport numpy as np\n\nimport nltk\nfrom nltk.tokenize import sent_tokenize\n\nnltk.download(\"punkt\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JyGMPbRXvGUL","outputId":"98f7fb96-fb8c-449a-d346-85763d1a1b6b"},"execution_count":29,"outputs":[{"name":"stderr","output_type":"stream","text":"[nltk_data] Downloading package punkt to /root/nltk_data...\n\n[nltk_data]   Package punkt is already up-to-date!\n"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")\n\nprint(f\"Features in cnn_dailymail : {dataset['train'].column_names}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["ae50112f680e446e87368ad81147235e","68cd6ca7aa40454195ccc26f9d870cb8","d7e6521389644dcaabe20c16fc20a3eb","13c185bb27074738998f4eb99c007505","5ccbc79e76f44dcf86ccc02be27b4910","3ff1d017bfda485bb965e897f14e3f70","ae75682934dc4077967b76fdbd194233","ef044cc6232249d4a80cb876dc889395","4008c0bbaea645a4bd95c26672cce12e","7597e26176f643a4873a9b11a5778af8","c02fa16b6d0a497e89e55c63b0427ddf"]},"id":"2cJKBLSCvGUO","outputId":"dc143cad-954c-4573-fe96-cc2761228956"},"execution_count":30,"outputs":[{"name":"stderr","output_type":"stream","text":"WARNING:datasets.builder:Using custom data configuration default\n\nWARNING:datasets.builder:Reusing dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/default/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae50112f680e446e87368ad81147235e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{}},{"name":"stdout","output_type":"stream","text":"Features in cnn_dailymail : ['article', 'highlights', 'id']\n"}]},{"cell_type":"code","source":"sample = dataset[\"train\"][1]\nprint(f\"\"\"\nArticle (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\n\"\"\")\nprint(sample[\"article\"][:500])\nprint(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\nprint(sample[\"highlights\"])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NpbiUHKDvGUO","outputId":"9698dac0-5c92-4f3a-89dc-a8996b14d4f3"},"execution_count":31,"outputs":[{"name":"stdout","output_type":"stream","text":"\n\nArticle (excerpt of 500 characters, total length: 4051):\n\n\n\nEditor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s\n\n\n\nSummary (length: 281):\n\nMentally ill inmates in Miami are housed on the \"forgotten floor\"\n\nJudge Steven Leifman says most are there as a result of \"avoidable felonies\"\n\nWhile CNN tours facility, patient shouts: \"I am the son of the president\"\n\nLeifman says the system is unjust and he's fighting for change .\n"}]},{"cell_type":"markdown","source":"-------------------\n\n## Text Summarization Pipelines\n","metadata":{"id":"YZNdu7bcvGUP"}},{"cell_type":"code","source":"sample_text = dataset[\"train\"][1][\"article\"][:1000]\n\n# We'll collect the generated summaries of each model in a dictionary\nsummaries = {}","metadata":{"id":"VR4hgH04vGUQ"},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### Summarization Baseline\n","metadata":{"id":"Tr1g3imGvGUR"}},{"cell_type":"code","source":"def baseline_summary_three_sent(text):\n    return \"\\n\".join(sent_tokenize(text)[:3])","metadata":{"id":"9aUXF1bQ0geQ"},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"summaries['baseline'] = baseline_summary_three_sent(sample_text)\n\nsummaries['baseline']","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"cBIan-VI0gbU","outputId":"22fda354-c05b-418e-c8b7-70bf0a153504"},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Editor\\'s note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\\nHere, Soledad O\\'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\\nMIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"'"]},"metadata":{}}]},{"cell_type":"markdown","source":"# GPT-2","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline, set_seed\n\nset_seed(42)\n\npipe = pipeline('text-generation', model = 'gpt2-medium' )\n\ngpt2_query = sample_text + \"\\nTL;DR:\\n\"\n\npipe_out = pipe(gpt2_query, max_length = 512, clean_up_tokenization_spaces = True)\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DccrU9QR0gYY","outputId":"f11bb1f5-8061-47aa-cc23-5e8101865c05"},"execution_count":35,"outputs":[{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"}]},{"cell_type":"code","source":"pipe_out","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eMrXmX0l0gVd","outputId":"6241794e-4899-424e-edcf-42bc1c3599a1"},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":["[{'generated_text': 'Editor\\'s note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O\\'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most severe mental illnesses are incarcerated until they\\'re ready to appear in court. Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\" He says the arrests often result from confrontations with police. Mentally ill people often won\\'t do what they\\'re told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow dir\\nTL;DR:\\nMIAMI-DADE, Florida | April 13, 2012 -- Some inmates are locked up in solitary confinement, where they must be isolated from the world for six months before they\\'re released onto the general jail population to participate in other inmates. Others are housed in \"theforgotten floor,\" the top floor of the pretrial facility that is also used by criminal offenders. What makes these inmates separate is their medical needs. They\\'re given special medications to treat their mental illness, but it\\'s only in those cases where necessary to take certain medications themselves for the very dangerous condition. These medications can lead to anaphylaxis or dangerous reactions if taken by people who are on them alone. A mentally ill person like John Brown, a convicted felon with severe mental illness. He spends four months in the \"forgotten floor\" and is charged with being a felon, disorderly conduct, assault with a deadly weapon (a gun), possession of child pornography, resisting arrest, and possession of marijuana. Brown was in the second floor when he fell asleep in bed. On April 11, his bed fell over and he was arrested and held until jail officials could check on him. After his detention, Brown refused to return to court the next morning to answer the charges. \"I won\\'t be back at all,\" Brown said. \"There will be no new hearings or there will be no court.\" This episode will air on January 18, 2013 on CNN\\'s Inside Story.'}]"]},"metadata":{}}]},{"cell_type":"code","source":"pipe_out[0][\"generated_text\"][len(gpt2_query) :]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"nZtMSEro0gSu","outputId":"a4de6061-86bc-4e67-e843-81b7b310b8d5"},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'MIAMI-DADE, Florida | April 13, 2012 -- Some inmates are locked up in solitary confinement, where they must be isolated from the world for six months before they\\'re released onto the general jail population to participate in other inmates. Others are housed in \"theforgotten floor,\" the top floor of the pretrial facility that is also used by criminal offenders. What makes these inmates separate is their medical needs. They\\'re given special medications to treat their mental illness, but it\\'s only in those cases where necessary to take certain medications themselves for the very dangerous condition. These medications can lead to anaphylaxis or dangerous reactions if taken by people who are on them alone. A mentally ill person like John Brown, a convicted felon with severe mental illness. He spends four months in the \"forgotten floor\" and is charged with being a felon, disorderly conduct, assault with a deadly weapon (a gun), possession of child pornography, resisting arrest, and possession of marijuana. Brown was in the second floor when he fell asleep in bed. On April 11, his bed fell over and he was arrested and held until jail officials could check on him. After his detention, Brown refused to return to court the next morning to answer the charges. \"I won\\'t be back at all,\" Brown said. \"There will be no new hearings or there will be no court.\" This episode will air on January 18, 2013 on CNN\\'s Inside Story.'"]},"metadata":{}}]},{"cell_type":"code","source":"summaries['gpt2'] = \"\\n\".join(sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))","metadata":{"id":"K5jwOJpA0gPg"},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# T5","metadata":{}},{"cell_type":"code","source":"pipe = pipeline('summarization', model = 't5-small' )\n\npipe_out = pipe(sample_text)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h6j9VqdQ0gM5","outputId":"1b101ada-d3a1-4e1d-a9c4-268812790d89"},"execution_count":39,"outputs":[{"name":"stderr","output_type":"stream","text":"/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5_fast.py:166: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n\n- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n\n  FutureWarning,\n"}]},{"cell_type":"code","source":"pipe_out","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lreykJlF0gJp","outputId":"bf1f56f0-f251-44c5-d0bf-24d9bb000eb1"},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":["[{'summary_text': \"inmates with the most severe mental illnesses are incarcerated until they're ready to appear in court . most often, they face drug charges or charges of assaulting an officer . mentally ill people become more paranoid, delusional, and less likely to follow dir .\"}]"]},"metadata":{}}]},{"cell_type":"code","source":"summaries['t5'] = 'n'.join(sent_tokenize(pipe_out[0]['summary_text']))","metadata":{"id":"veS7tqCk0gGT"},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# BART","metadata":{}},{"cell_type":"code","source":"pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\npipe_out = pipe(sample_text)\n","metadata":{"id":"t5OQKD6H6BSJ"},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"pipe_out","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SoZO5EUR6BLr","outputId":"b387e275-040e-4c7d-c482-95b0e536c7bf"},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":["[{'summary_text': 'Miami-Dade pretrial detention facility is dubbed the \"forgotten floor\" Here, inmates with the most severe mental illnesses are incarcerated. Most often, they face drug charges or charges of assaulting an officer. Judge Steven Leifman says the arrests often result from confrontations with police.'}]"]},"metadata":{}}]},{"cell_type":"code","source":"summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))","metadata":{"id":"WLOJIUyF6BIt"},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"summaries[\"bart\"]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"ZbGxe1q1MIWM","outputId":"345193a7-36c8-40e9-e3ae-8f3cc7768435"},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Miami-Dade pretrial detention facility is dubbed the \"forgotten floor\" Here, inmates with the most severe mental illnesses are incarcerated.\\nMost often, they face drug charges or charges of assaulting an officer.\\nJudge Steven Leifman says the arrests often result from confrontations with police.'"]},"metadata":{}}]},{"cell_type":"markdown","source":"# PEGASUS","metadata":{}},{"cell_type":"code","source":"pipe = pipeline('summarization', model=\"google/pegasus-cnn_dailymail\"  )\n\npipe_out = pipe(sample_text)","metadata":{"id":"Lox7RRHt6BF3"},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"pipe_out","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-WZQyrM36BCn","outputId":"51aab94d-94ce-4789-bffc-5d2253a6d617"},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":["[{'summary_text': 'Mentally ill inmates are housed on the \"forgotten floor\" of a Miami jail .<n>Judge Steven Leifman says the charges are usually \"avoidable felonies\"<n>He says the arrests often result from confrontations with police .<n>Mentally ill people often won\\'t do what they\\'re told when police arrive on the scene .'}]"]},"metadata":{}}]},{"cell_type":"code","source":"summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")","metadata":{"id":"8w49uN5u6A-z"},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"## Comparing Different Summaries","metadata":{"id":"OIdFjtn49b1I"},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"print(\"GROUND TRUTH\")\n\nprint(dataset['train'][1]['highlights'])\n\n\nfor model_name in summaries:\n    print(model_name.upper())\n    print(summaries[model_name])\n    ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ullRF6UO6A79","outputId":"fbe54ffa-27d2-4020-8c3e-0befc4a5931b"},"execution_count":50,"outputs":[{"name":"stdout","output_type":"stream","text":"GROUND TRUTH\n\nMentally ill inmates in Miami are housed on the \"forgotten floor\"\n\nJudge Steven Leifman says most are there as a result of \"avoidable felonies\"\n\nWhile CNN tours facility, patient shouts: \"I am the son of the president\"\n\nLeifman says the system is unjust and he's fighting for change .\n\nBASELINE\n\nEditor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\n\nHere, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\n\nMIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"\n\nGPT2\n\nMIAMI-DADE, Florida | April 13, 2012 -- Some inmates are locked up in solitary confinement, where they must be isolated from the world for six months before they're released onto the general jail population to participate in other inmates.\n\nOthers are housed in \"theforgotten floor,\" the top floor of the pretrial facility that is also used by criminal offenders.\n\nWhat makes these inmates separate is their medical needs.\n\nThey're given special medications to treat their mental illness, but it's only in those cases where necessary to take certain medications themselves for the very dangerous condition.\n\nThese medications can lead to anaphylaxis or dangerous reactions if taken by people who are on them alone.\n\nA mentally ill person like John Brown, a convicted felon with severe mental illness.\n\nHe spends four months in the \"forgotten floor\" and is charged with being a felon, disorderly conduct, assault with a deadly weapon (a gun), possession of child pornography, resisting arrest, and possession of marijuana.\n\nBrown was in the second floor when he fell asleep in bed.\n\nOn April 11, his bed fell over and he was arrested and held until jail officials could check on him.\n\nAfter his detention, Brown refused to return to court the next morning to answer the charges.\n\n\"I won't be back at all,\" Brown said.\n\n\"There will be no new hearings or there will be no court.\"\n\nThis episode will air on January 18, 2013 on CNN's Inside Story.\n\nT5\n\ninmates with the most severe mental illnesses are incarcerated until they're ready to appear in court .nmost often, they face drug charges or charges of assaulting an officer .nmentally ill people become more paranoid, delusional, and less likely to follow dir .\n\nBART\n\nMiami-Dade pretrial detention facility is dubbed the \"forgotten floor\" Here, inmates with the most severe mental illnesses are incarcerated.\n\nMost often, they face drug charges or charges of assaulting an officer.\n\nJudge Steven Leifman says the arrests often result from confrontations with police.\n\nPEGASUS\n\nMentally ill inmates are housed on the \"forgotten floor\" of a Miami jail.\n\nJudge Steven Leifman says the charges are usually \"avoidable felonies\"<n>He says the arrests often result from confrontations with police.\n\nMentally ill people often won't do what they're told when police arrive on the scene .\n"}]},{"cell_type":"markdown","source":"# SacreBLEU","metadata":{}},{"cell_type":"code","source":"\nfrom datasets import load_metric\n\nbleu_metric = load_metric(\"sacrebleu\")","metadata":{"id":"7S--atct6A42"},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"bleu_metric.add(prediction = [summaries[\"pegasus\"]], reference = [dataset['train'][1]['highlights'] ])\n\nresults = bleu_metric.compute(smooth_method = 'floor', smooth_value = 0 )\n\nresults['precision'] = [np.round(p , 2) for p in results['precisions'] ]\n\npd.DataFrame.from_dict(results, orient = 'index', columns = ['Value'] )","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"m4SyzdJ66A1y","outputId":"af2983a5-a930-4633-fcb6-c915ba7f77ab"},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-e35236e0-6ce8-4510-b068-0955044cee18\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>score</th>\n","      <td>18.73841</td>\n","    </tr>\n","    <tr>\n","      <th>counts</th>\n","      <td>[27, 14, 10, 6]</td>\n","    </tr>\n","    <tr>\n","      <th>totals</th>\n","      <td>[67, 66, 65, 64]</td>\n","    </tr>\n","    <tr>\n","      <th>precisions</th>\n","      <td>[40.298507462686565, 21.21212121212121, 15.384...</td>\n","    </tr>\n","    <tr>\n","      <th>bp</th>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>sys_len</th>\n","      <td>67</td>\n","    </tr>\n","    <tr>\n","      <th>ref_len</th>\n","      <td>57</td>\n","    </tr>\n","    <tr>\n","      <th>precision</th>\n","      <td>[40.3, 21.21, 15.38, 9.38]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e35236e0-6ce8-4510-b068-0955044cee18')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e35236e0-6ce8-4510-b068-0955044cee18 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e35236e0-6ce8-4510-b068-0955044cee18');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                        Value\n","score                                                18.73841\n","counts                                        [27, 14, 10, 6]\n","totals                                       [67, 66, 65, 64]\n","precisions  [40.298507462686565, 21.21212121212121, 15.384...\n","bp                                                        1.0\n","sys_len                                                    67\n","ref_len                                                    57\n","precision                          [40.3, 21.21, 15.38, 9.38]"]},"metadata":{}}]},{"cell_type":"markdown","source":"# ROUGE","metadata":{}},{"cell_type":"code","source":"rouge_metric = load_metric('rouge')","metadata":{"id":"1rJy54Bd9OkP"},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"## ROUGE-N\n\nWith ROUGE-N, the N represents the n-gram that we are using. For ROUGE-1 we would be measuring the match-rate of unigrams between our model output and reference.\n\nROUGE-2 and ROUGE-3 would use bigrams and trigrams respectively.\n\n\n## ROUGE-L\n\nROUGE-L measures the longest common subsequence (LCS) between our model output and reference. All this means is that we count the longest sequence of tokens that is shared between both:\n\n\nIn the HF Datasets implementation, two variations of ROUGE are\ncalculated: one calculates the score per sentence and averages it for the\nsummaries (ROUGE-L), and the other calculates it directly over the whole\nsummary (ROUGE-Lsum).\n","metadata":{"id":"GqZPSwDONnq8"}},{"cell_type":"code","source":"rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n\nreference = dataset['train'][1]['highlights']\n\nrecords = []\n\nfor model_name in summaries:\n    rouge_metric.add(prediction = summaries[model_name], reference = reference )\n    score = rouge_metric.compute()\n    rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n    print('rouge_dict ', rouge_dict )\n    records.append(rouge_dict)\n\npd.DataFrame.from_records(records, index = summaries.keys() )","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"CCNutX-cNnNv","outputId":"4b31402a-bb93-4765-8244-2d6415ee51e7"},"execution_count":56,"outputs":[{"name":"stdout","output_type":"stream","text":"rouge_dict  {'rouge1': 0.365079365079365, 'rouge2': 0.14516129032258066, 'rougeL': 0.20634920634920634, 'rougeLsum': 0.2857142857142857}\n\nrouge_dict  {'rouge1': 0.1836734693877551, 'rouge2': 0.0410958904109589, 'rougeL': 0.10204081632653061, 'rougeLsum': 0.17006802721088435}\n\nrouge_dict  {'rouge1': 0.1758241758241758, 'rouge2': 0.0, 'rougeL': 0.13186813186813187, 'rougeLsum': 0.15384615384615383}\n\nrouge_dict  {'rouge1': 0.3655913978494624, 'rouge2': 0.13186813186813184, 'rougeL': 0.2150537634408602, 'rougeLsum': 0.3225806451612903}\n\nrouge_dict  {'rouge1': 0.5, 'rouge2': 0.24489795918367346, 'rougeL': 0.36000000000000004, 'rougeLsum': 0.46}\n"},{"execution_count":56,"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-7279dded-a102-4eda-a78b-1e6fc87df40a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rouge1</th>\n","      <th>rouge2</th>\n","      <th>rougeL</th>\n","      <th>rougeLsum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>baseline</th>\n","      <td>0.365079</td>\n","      <td>0.145161</td>\n","      <td>0.206349</td>\n","      <td>0.285714</td>\n","    </tr>\n","    <tr>\n","      <th>gpt2</th>\n","      <td>0.183673</td>\n","      <td>0.041096</td>\n","      <td>0.102041</td>\n","      <td>0.170068</td>\n","    </tr>\n","    <tr>\n","      <th>t5</th>\n","      <td>0.175824</td>\n","      <td>0.000000</td>\n","      <td>0.131868</td>\n","      <td>0.153846</td>\n","    </tr>\n","    <tr>\n","      <th>bart</th>\n","      <td>0.365591</td>\n","      <td>0.131868</td>\n","      <td>0.215054</td>\n","      <td>0.322581</td>\n","    </tr>\n","    <tr>\n","      <th>pegasus</th>\n","      <td>0.500000</td>\n","      <td>0.244898</td>\n","      <td>0.360000</td>\n","      <td>0.460000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7279dded-a102-4eda-a78b-1e6fc87df40a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7279dded-a102-4eda-a78b-1e6fc87df40a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7279dded-a102-4eda-a78b-1e6fc87df40a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["            rouge1    rouge2    rougeL  rougeLsum\n","baseline  0.365079  0.145161  0.206349   0.285714\n","gpt2      0.183673  0.041096  0.102041   0.170068\n","t5        0.175824  0.000000  0.131868   0.153846\n","bart      0.365591  0.131868  0.215054   0.322581\n","pegasus   0.500000  0.244898  0.360000   0.460000"]},"metadata":{}}]},{"cell_type":"code","source":"def calculate_metric_on_baseline_test_ds(dataset, metric, column_text = 'article', column_summary = 'highlights' ):\n    \"\"\"\n    This function calculates a specified metric on a baseline test dataset for a Natural Language Processing (NLP) task.\n    It assumes the task is a text summarization task, where the goal is to generate a summary (e.g., highlights) from a text (e.g., article).\n\n    Parameters:\n    dataset (pandas.DataFrame): The test dataset. It should contain a column for the text and a column for the true summary.\n    metric (datasets.Metric): The metric to calculate. This should be a metric object from the Hugging Face datasets library.\n    column_text (str, optional): The name of the column in the dataset that contains the text. Defaults to 'article'.\n    column_summary (str, optional): The name of the column in the dataset that contains the true summary. Defaults to 'highlights'.\n\n    Returns:\n    score (float): The calculated score of the metric on the test dataset.\n    \"\"\"\n    summaries = [baseline_summary_three_sent(text) for text in dataset[column_text] ]\n\n    metric.add_batch(predictions = summaries, references = dataset[column_summary] )\n\n    score = metric.compute()\n    return score","metadata":{"id":"k_yjJmEu9OhV"},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"test_sampled = dataset['train'].shuffle(seed = 42).select(range(1000))\n\nscore = calculate_metric_on_baseline_test_ds(test_sampled, rouge_metric )\n\nrouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n\npd.DataFrame.from_dict(rouge_dict, orient = 'index' , columns = ['baseline'] ).T","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"e8LVc-_F9Oek","outputId":"80c0818b-630d-4873-bf3e-bda3c071dd0c"},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-de1b1962-e2b7-44c2-bd14-e6b759ef826c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rouge1</th>\n","      <th>rouge2</th>\n","      <th>rougeL</th>\n","      <th>rougeLsum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>baseline</th>\n","      <td>0.253995</td>\n","      <td>0.100642</td>\n","      <td>0.165754</td>\n","      <td>0.231571</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de1b1962-e2b7-44c2-bd14-e6b759ef826c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-de1b1962-e2b7-44c2-bd14-e6b759ef826c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-de1b1962-e2b7-44c2-bd14-e6b759ef826c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["            rouge1    rouge2    rougeL  rougeLsum\n","baseline  0.253995  0.100642  0.165754   0.231571"]},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef generate_batch_sized_chunks(list_of_elements, batch_size):\n    \"\"\"split the dataset into smaller batches that we can process simultaneously\n    Yield successive batch-sized chunks from list_of_elements.\n    \n    Generator function to yield successive batch-sized chunks from list_of_elements.\n\n    Parameters:\n    list_of_elements (list): List of elements to be divided into chunks.\n    batch_size (int): The size of each chunk.\n\n    Yields:\n    list: Batch-sized chunk from list_of_elements.\n    \n    \"\"\"\n    for i in range(0, len(list_of_elements), batch_size):\n        yield list_of_elements[i : i + batch_size]\n\ndef calculate_metric_on_test_ds(dataset, metric, model, tokenizer, \n                               batch_size=16, device=device, \n                               column_text=\"article\", \n                               column_summary=\"highlights\"):\n    \"\"\"\n    Function to calculate a specified metric on a test dataset for a Natural Language Processing (NLP) task.\n    It assumes the task is a text summarization task, where the goal is to generate a summary from a text.\n\n    Parameters:\n    dataset (pandas.DataFrame): The test dataset. It should contain a column for the text and a column for the true summary.\n    metric (datasets.Metric): The metric to calculate. This should be a metric object from the Hugging Face datasets library.\n    model (transformers.PreTrainedModel): The transformer model to use for text generation.\n    tokenizer (transformers.PreTrainedTokenizer): The tokenizer corresponding to the model.\n    batch_size (int, optional): The size of the batches to use for processing. Defaults to 16.\n    device (str, optional): The device to run the model on. Defaults to the output of torch.cuda.is_available().\n    column_text (str, optional): The name of the column in the dataset that contains the text. Defaults to 'article'.\n    column_summary (str, optional): The name of the column in the dataset that contains the true summary. Defaults to 'highlights'.\n\n    Returns:\n    score (float): The calculated score of the metric on the test dataset.\n    \"\"\"\n    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n\n    for article_batch, target_batch in tqdm(\n        zip(article_batches, target_batches), total=len(article_batches)):\n        \n        inputs = tokenizer(article_batch, max_length=1024,  truncation=True, \n                        padding=\"max_length\", return_tensors=\"pt\")\n        \n        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n                         attention_mask=inputs[\"attention_mask\"].to(device), \n                         length_penalty=0.8, num_beams=8, max_length=128)\n        ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n        \n        # Finally, we decode the generated texts, \n        # replace the <n> token, and add the decoded texts with the references to the metric.\n        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, \n                                clean_up_tokenization_spaces=True) \n               for s in summaries]      \n        \n        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n        \n        \n        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n        \n    #  Finally compute and return the ROUGE scores.\n    score = metric.compute()\n    return score","metadata":{"id":"dQlqJ-6cNW5H"},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nmodel_ckpt = \"google/pegasus-cnn_dailymail\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n\nmodel_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n\nscore = calculate_metric_on_test_ds(test_sampled, rouge_metric, \n                                   model_pegasus, tokenizer, batch_size=8)\n\nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n\n# At the end, we compute and return the ROUGE scores.\npd.DataFrame(rouge_dict, index=[\"pegasus\"])","metadata":{"id":"Hud5crl3NW2Y"},"execution_count":null,"outputs":[]}]}